{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "extreme-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import twitter_credentials\n",
    "user_file = 'twitter_user.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "military-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(twitter_credentials.CONSUMER_KEY, twitter_credentials.CONSUMER_SECRET)\n",
    "auth.set_access_token(twitter_credentials.ACCESS_TOKEN_KEY, twitter_credentials.ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "informative-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_file,'r') as uf:\n",
    "    user_list = json.load(uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaging-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(userid):\n",
    "    cursor = tweepy.Cursor(api.user_timeline,id = userid,tweet_mode = 'extended').items(200)\n",
    "    tweet_list = []\n",
    "    for i in cursor:\n",
    "        tweet_list.append(i.full_text)\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "homeless-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "tk = TweetTokenizer(strip_handles = True)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "binary-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment(tweet_list):\n",
    "    overall_sentiment_score = 0\n",
    "    for tweet in tweet_list:\n",
    "        sentiment_score = sia.polarity_scores(tweet)\n",
    "        overall_sentiment_score += sentiment_score['compound']\n",
    "        \n",
    "    if overall_sentiment_score == 0:\n",
    "        overall_sentiment = 'neutral'\n",
    "    elif overall_sentiment_score > 0:\n",
    "        overall_sentiment = 'positive'\n",
    "    else:\n",
    "        overall_sentiment = 'negative'\n",
    "\n",
    "    return overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "upper-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topten(tweet_list):\n",
    "    full_text = []\n",
    "    for tweet in tweet_list:\n",
    "        tweet_tokens = tk.tokenize(tweet)\n",
    "        filtered_sentence = []\n",
    "        for w in tweet_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        full_text += filtered_sentence\n",
    "    full_textDist = nltk.FreqDist(full_text)\n",
    "    return full_textDist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "printable-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in user_list:\n",
    "    userid = user['user']\n",
    "    tweet_list = get_tweets(userid)\n",
    "    user['overall_sentiment'] = tweet_sentiment(tweet_list)\n",
    "    user['most_common'] = topten(tweet_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
